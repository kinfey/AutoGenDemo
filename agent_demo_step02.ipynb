{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyautogen in /Users/lokinfey/conda/envs/autogenenv/lib/python3.10/site-packages (0.2.11)\n",
      "Requirement already satisfied: diskcache in /Users/lokinfey/conda/envs/autogenenv/lib/python3.10/site-packages (from pyautogen) (5.6.3)\n",
      "Requirement already satisfied: docker in /Users/lokinfey/conda/envs/autogenenv/lib/python3.10/site-packages (from pyautogen) (7.0.0)\n",
      "Requirement already satisfied: flaml in /Users/lokinfey/conda/envs/autogenenv/lib/python3.10/site-packages (from pyautogen) (2.1.1)\n",
      "Requirement already satisfied: openai>=1.3 in /Users/lokinfey/conda/envs/autogenenv/lib/python3.10/site-packages (from pyautogen) (1.11.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.10 in /Users/lokinfey/conda/envs/autogenenv/lib/python3.10/site-packages (from pyautogen) (1.10.13)\n",
      "Requirement already satisfied: python-dotenv in /Users/lokinfey/conda/envs/autogenenv/lib/python3.10/site-packages (from pyautogen) (1.0.0)\n",
      "Requirement already satisfied: termcolor in /Users/lokinfey/conda/envs/autogenenv/lib/python3.10/site-packages (from pyautogen) (2.3.0)\n",
      "Requirement already satisfied: tiktoken in /Users/lokinfey/conda/envs/autogenenv/lib/python3.10/site-packages (from pyautogen) (0.5.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/lokinfey/conda/envs/autogenenv/lib/python3.10/site-packages (from openai>=1.3->pyautogen) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/lokinfey/conda/envs/autogenenv/lib/python3.10/site-packages (from openai>=1.3->pyautogen) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/lokinfey/conda/envs/autogenenv/lib/python3.10/site-packages (from openai>=1.3->pyautogen) (0.25.1)\n",
      "Requirement already satisfied: sniffio in /Users/lokinfey/conda/envs/autogenenv/lib/python3.10/site-packages (from openai>=1.3->pyautogen) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/lokinfey/conda/envs/autogenenv/lib/python3.10/site-packages (from openai>=1.3->pyautogen) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/lokinfey/conda/envs/autogenenv/lib/python3.10/site-packages (from openai>=1.3->pyautogen) (4.8.0)\n",
      "Requirement already satisfied: packaging>=14.0 in /Users/lokinfey/conda/envs/autogenenv/lib/python3.10/site-packages (from docker->pyautogen) (23.2)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/lokinfey/conda/envs/autogenenv/lib/python3.10/site-packages (from docker->pyautogen) (2.31.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/lokinfey/conda/envs/autogenenv/lib/python3.10/site-packages (from docker->pyautogen) (1.26.18)\n",
      "Requirement already satisfied: NumPy>=1.17.0rc1 in /Users/lokinfey/conda/envs/autogenenv/lib/python3.10/site-packages (from flaml->pyautogen) (1.26.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/lokinfey/conda/envs/autogenenv/lib/python3.10/site-packages (from tiktoken->pyautogen) (2023.10.3)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/lokinfey/conda/envs/autogenenv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.3->pyautogen) (3.4)\n",
      "Requirement already satisfied: exceptiongroup in /Users/lokinfey/conda/envs/autogenenv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.3->pyautogen) (1.1.3)\n",
      "Requirement already satisfied: certifi in /Users/lokinfey/conda/envs/autogenenv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai>=1.3->pyautogen) (2023.7.22)\n",
      "Requirement already satisfied: httpcore in /Users/lokinfey/conda/envs/autogenenv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai>=1.3->pyautogen) (1.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/lokinfey/conda/envs/autogenenv/lib/python3.10/site-packages (from requests>=2.26.0->docker->pyautogen) (3.3.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/lokinfey/conda/envs/autogenenv/lib/python3.10/site-packages (from httpcore->httpx<1,>=0.23.0->openai>=1.3->pyautogen) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install pyautogen -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import autogen\n",
    "from autogen.agentchat import AssistantAgent\n",
    "from autogen.agentchat.contrib.multimodal_conversable_agent import MultimodalConversableAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list_4v = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4-vision-preview\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4-0125-preview\", \"gpt-3.5-turbo-0125\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "llm_config = {\"config_list\": config_list, \"cache_seed\": 42}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "commander = AssistantAgent(\n",
    "            name=\"Commander\",\n",
    "            system_message = \"You are a running Python agent. , help  me to run generative python code\",\n",
    "            llm_config=llm_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "coder = AssistantAgent(\n",
    "            name=\"Coder\",\n",
    "            system_message = \"You are a Python code agent. , help  me to generative python code\",\n",
    "            llm_config=llm_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checker = MultimodalConversableAgent(\n",
    "    name=\"Checker\",\n",
    "    max_consecutive_auto_reply=1,\n",
    "    llm_config={\"config_list\": config_list_4v, \"temperature\": 0.5, \"max_tokens\": 300},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"User_proxy\",\n",
    "    system_message=\"You are a production safety administrator.\",\n",
    "    human_input_mode=\"NEVER\",  # Try between ALWAYS or NEVER\n",
    "    max_consecutive_auto_reply=30,\n",
    "    code_execution_config={\n",
    "        \"work_dir\": \"coding\",\n",
    "        \"use_docker\": False\n",
    "    },  # Please set use_docker=True if docker is available to run the generated code. Using docker is safer than running the generated code directly.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupchat = autogen.GroupChat(agents=[user_proxy, checker,coder, commander], messages=[], max_round=10)\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "tell me how many people are in the image. who's not wearing a helmet on their heads?\n",
      "<img https://i.cbc.ca/1.6704834.1672945320!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/sikh-helmets-tina-singh.jpg>. Tell me the location of who not wearing a helmet on their heads on the image. Share the x_min, y_min, x_max and y_max in 0-1 normalized space for not wearing person. Only return the numbers, nothing else. Then run python code  to download this image, use opencv to label it based on the returned space value , save the label image\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mChecker\u001b[0m (to chat_manager):\n",
      "\n",
      "There are three people in the image. The person not wearing a helmet is the woman in the center.\n",
      "\n",
      "For the woman not wearing a helmet, the coordinates in normalized space are approximately:\n",
      "x_min: 0.35\n",
      "y_min: 0.15\n",
      "x_max: 0.65\n",
      "y_max: 0.85\n",
      "\n",
      "I'm sorry, but I can't run Python code or perform any actions like downloading images or using OpenCV to label images. However, I can guide you on how to do it yourself. Would you like to know how to write and run the Python code to perform these tasks?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCoder\u001b[0m (to chat_manager):\n",
      "\n",
      "Sure! Here's how you can write a Python code to download the image, label the person not wearing a helmet based on the provided normalized space coordinates, and save the labeled image using OpenCV:\n",
      "\n",
      "```python\n",
      "import cv2\n",
      "\n",
      "# Download the image using a library like requests\n",
      "import requests\n",
      "\n",
      "image_url = \"https://i.cbc.ca/1.6704834.1672945320!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/sikh-helmets-tina-singh.jpg\"\n",
      "response = requests.get(image_url)\n",
      "\n",
      "with open('image.jpg', 'wb') as f:\n",
      "    f.write(response.content)\n",
      "\n",
      "# Load the image using OpenCV\n",
      "image = cv2.imread('image.jpg')\n",
      "\n",
      "# Define the bounding box coordinates in normalized space\n",
      "x_min = 0.35\n",
      "y_min = 0.15\n",
      "x_max = 0.65\n",
      "y_max = 0.85\n",
      "\n",
      "# Get the image dimensions\n",
      "height, width, _ = image.shape\n",
      "\n",
      "# Convert normalized coordinates to pixel coordinates\n",
      "x1 = int(x_min * width)\n",
      "y1 = int(y_min * height)\n",
      "x2 = int(x_max * width)\n",
      "y2 = int(y_max * height)\n",
      "\n",
      "# Draw the bounding box on the image\n",
      "color = (0, 255, 0)  # Green color\n",
      "thickness = 2\n",
      "cv2.rectangle(image, (x1, y1), (x2, y2), color, thickness)\n",
      "\n",
      "# Save the labeled image\n",
      "cv2.imwrite('labeled_image.jpg', image)\n",
      "\n",
      "print(\"Image labeled and saved as labeled_image.jpg\")\n",
      "```\n",
      "\n",
      "You can copy this code into a Python script, run it, and it will download the image, label the person not wearing a helmet, and save the labeled image as \"labeled_image.jpg\" in the same directory where the script is executed.\n",
      "\n",
      "Make sure you have the necessary Python libraries like OpenCV and requests installed to run this code successfully. Let me know if you need further assistance!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCommander\u001b[0m (to chat_manager):\n",
      "\n",
      "If you run this code, it will download the provided image, label the person not wearing a helmet based on the given coordinates, and save the labeled image as 'labeled_image.jpg'. Let me know if you encounter any issues or need further assistance!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "Image labeled and saved as labeled_image.jpg\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GroupChat select_speaker failed to resolve the next speaker's name. This is because the speaker selection OAI call returned:\n",
      "This conversation has been successfully completed. No further action is required.\n",
      "/Users/lokinfey/conda/envs/autogenenv/lib/python3.10/site-packages/autogen/agentchat/conversable_agent.py:838: UserWarning: No summary_method provided or summary_method is not supported: \n",
      "  warnings.warn(\"No summary_method provided or summary_method is not supported: \")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_history=[{'content': \"tell me how many people are in the image. who's not wearing a helmet on their heads?\\n<img https://i.cbc.ca/1.6704834.1672945320!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/sikh-helmets-tina-singh.jpg>. Tell me the location of who not wearing a helmet on their heads on the image. Share the x_min, y_min, x_max and y_max in 0-1 normalized space for not wearing person. Only return the numbers, nothing else. Then run python code  to download this image, use opencv to label it based on the returned space value , save the label image\", 'role': 'assistant'}, {'content': \"There are three people in the image. The person not wearing a helmet is the woman in the center.\\n\\nFor the woman not wearing a helmet, the coordinates in normalized space are approximately:\\nx_min: 0.35\\ny_min: 0.15\\nx_max: 0.65\\ny_max: 0.85\\n\\nI'm sorry, but I can't run Python code or perform any actions like downloading images or using OpenCV to label images. However, I can guide you on how to do it yourself. Would you like to know how to write and run the Python code to perform these tasks?\", 'name': 'Checker', 'role': 'user'}, {'content': 'Sure! Here\\'s how you can write a Python code to download the image, label the person not wearing a helmet based on the provided normalized space coordinates, and save the labeled image using OpenCV:\\n\\n```python\\nimport cv2\\n\\n# Download the image using a library like requests\\nimport requests\\n\\nimage_url = \"https://i.cbc.ca/1.6704834.1672945320!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/sikh-helmets-tina-singh.jpg\"\\nresponse = requests.get(image_url)\\n\\nwith open(\\'image.jpg\\', \\'wb\\') as f:\\n    f.write(response.content)\\n\\n# Load the image using OpenCV\\nimage = cv2.imread(\\'image.jpg\\')\\n\\n# Define the bounding box coordinates in normalized space\\nx_min = 0.35\\ny_min = 0.15\\nx_max = 0.65\\ny_max = 0.85\\n\\n# Get the image dimensions\\nheight, width, _ = image.shape\\n\\n# Convert normalized coordinates to pixel coordinates\\nx1 = int(x_min * width)\\ny1 = int(y_min * height)\\nx2 = int(x_max * width)\\ny2 = int(y_max * height)\\n\\n# Draw the bounding box on the image\\ncolor = (0, 255, 0)  # Green color\\nthickness = 2\\ncv2.rectangle(image, (x1, y1), (x2, y2), color, thickness)\\n\\n# Save the labeled image\\ncv2.imwrite(\\'labeled_image.jpg\\', image)\\n\\nprint(\"Image labeled and saved as labeled_image.jpg\")\\n```\\n\\nYou can copy this code into a Python script, run it, and it will download the image, label the person not wearing a helmet, and save the labeled image as \"labeled_image.jpg\" in the same directory where the script is executed.\\n\\nMake sure you have the necessary Python libraries like OpenCV and requests installed to run this code successfully. Let me know if you need further assistance!', 'name': 'Coder', 'role': 'user'}, {'content': \"If you run this code, it will download the provided image, label the person not wearing a helmet based on the given coordinates, and save the labeled image as 'labeled_image.jpg'. Let me know if you encounter any issues or need further assistance!\", 'name': 'Commander', 'role': 'user'}, {'content': 'exitcode: 0 (execution succeeded)\\nCode output: \\nImage labeled and saved as labeled_image.jpg\\n', 'role': 'assistant'}, {'content': '', 'role': 'assistant'}, {'content': '', 'role': 'assistant'}], summary='', cost=({'total_cost': 0, 'gpt-3.5-turbo-0125': {'cost': 0, 'prompt_tokens': 5561, 'completion_tokens': 23, 'total_tokens': 5584}}, {'total_cost': 0, 'gpt-3.5-turbo-0125': {'cost': 0, 'prompt_tokens': 5561, 'completion_tokens': 23, 'total_tokens': 5584}}), human_input=[])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_proxy.initiate_chat(\n",
    "    manager,\n",
    "    message=\"\"\"tell me how many people are in the image. who's not wearing a helmet on their heads?\n",
    "<img https://i.cbc.ca/1.6704834.1672945320!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/sikh-helmets-tina-singh.jpg>. Tell me the location of who not wearing a helmet on their heads on the image. Share the x_min, y_min, x_max and y_max in 0-1 normalized space for not wearing person. Only return the numbers, nothing else. Then run python code  to download this image, use opencv to label it based on the returned space value , save the label image\"\"\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogenenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
